{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vilma\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import pandas as pd\n",
    "model = Doc2Vec.load('./surveyVectors.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('vectorComments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment                                            comment  \\\n",
      "0          1  She present class materials with powerpoint wh...   \n",
      "\n",
      "                                 vectorized_comments  \n",
      "0  [0.0368987, -0.134596, 0.0120176, -0.0541564, ...  \n"
     ]
    }
   ],
   "source": [
    "print (df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vilma\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Cross validation\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import pickle\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with knn:\n",
    "- doc2vec vectors\n",
    "- k values used are 2, 3, 7, 9\n",
    "- Cross validation fold=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "#This stores a list from 1 to 10, which will be used as k values from 1 to 10\n",
    "k_range=list(range(1,10))\n",
    "print(k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
     ]
    }
   ],
   "source": [
    "#Creates a dictionary, tuple of the key of nn and its values\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create knn classifier\n",
    "knn=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use knn classifier, parameters from param_grid, k-fold = 10, and precision as the metrics score\n",
    "grid=GridSearchCV(knn,param_grid,cv=StratifiedKFold(n_splits=5),scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert data arrays to lists\n",
    "X=df[\"vectorized_comments\"].T.tolist()\n",
    "y=df[\"sentiment\"].T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the classifier 'grid' created in line 15 to fit our data\n",
    "#X - represents the comments\n",
    "#y - represents the labels (1 or 0)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEXCAYAAAC+mHPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2400b8653c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results of all folds for all knn values, for an specific metric\n",
    "labels = []\n",
    "for i in range(1,9):\n",
    "    plt.plot([1,2,3,4,5], grid.grid_scores_[i].cv_validation_scores)\n",
    "    labels.append(r'$knn = %i$' % (i))\n",
    "\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Precision')\n",
    "plt.legend(labels,ncol=4, loc='upper center', bbox_to_anchor=[0.5, 1.1], \n",
    "           columnspacing=1.0, labelspacing=0.0, handletextpad=0.0,\n",
    "           handlelength=1.5, fancybox=True, shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.89016, std: 0.02070, params: {'n_neighbors': 1},\n",
       " mean: 0.85794, std: 0.01338, params: {'n_neighbors': 2},\n",
       " mean: 0.89848, std: 0.00887, params: {'n_neighbors': 3},\n",
       " mean: 0.89041, std: 0.01898, params: {'n_neighbors': 4},\n",
       " mean: 0.90396, std: 0.01233, params: {'n_neighbors': 5},\n",
       " mean: 0.89998, std: 0.01518, params: {'n_neighbors': 6},\n",
       " mean: 0.90570, std: 0.00931, params: {'n_neighbors': 7},\n",
       " mean: 0.89922, std: 0.00830, params: {'n_neighbors': 8},\n",
       " mean: 0.90517, std: 0.00947, params: {'n_neighbors': 9}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the complete results (list of named tuples)\n",
    "#Shows the mean value for each k value, as well as the standard deviation, and its parameters\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 3}\n",
      "[ 0.89473684  0.9025641   0.89583333  0.88648649  0.91304348]\n",
      "0.8984794024\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# examine the first tuple, when k=1\n",
    "print(grid.grid_scores_[2].parameters)\n",
    "print(grid.grid_scores_[2].cv_validation_scores)\n",
    "print(grid.grid_scores_[2].mean_validation_score)\n",
    "print(len(grid.grid_scores_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89016160862375782, 0.85793603154036224, 0.89847940240006308, 0.89041226462821188, 0.90396083337865485, 0.89997663197141597, 0.90569939541911004, 0.89921899171206077, 0.90516721145802115]\n"
     ]
    }
   ],
   "source": [
    "# create a list of the mean scores only\n",
    "grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]\n",
    "print(grid_mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905699395419\n",
      "{'n_neighbors': 7}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[ 18  71]\n",
      " [  7 447]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = grid.best_estimator_.predict(X)\n",
    "print(y)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Random Forest Classifier (RFC)\n",
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting.\n",
    "\n",
    "bootstrap = [True] ---> samples are drawn with replacement if bootstrap=True (default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=1, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': [2], 'n_estimators': [200, 400], 'min_samples_leaf': [1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [200,400],\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_samples_split': [2]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(RFC(verbose=1,n_jobs=1), param_grid=parameters, cv=StratifiedKFold(n_splits=5), scoring='f1')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90641130497582734, 0.91099686715146255] Mean of all scores for each cv fold\n"
     ]
    }
   ],
   "source": [
    "# create a list of the mean scores only\n",
    "grid_mean_scores = [result.mean_validation_score for result in clf.grid_scores_]\n",
    "print(grid_mean_scores,\"Mean of all scores for each cv fold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.910996867151\n",
      "{'min_samples_split': 2, 'n_estimators': 400, 'min_samples_leaf': 1}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=400, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=1, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 89   0]\n",
      " [  0 454]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "y1_pred = clf.best_estimator_.predict(X)\n",
    "print(confusion_matrix(y, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent Classifier (SGDC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup 5-fold stratified cross validation\n",
    "cross_v = StratifiedKFold(n_splits=5) #Takes group information into account to avoid building folds with imbalanced class distributions (for binary or multiclass classification tasks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a parameter grid to search over\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    'loss': ('log', 'hinge'), #function that gives the amount of error rate\n",
    "    'penalty': ['l1', 'l2', 'elasticnet']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create SGDC classifier using logistic regression and hinge\n",
    "grid_search = GridSearchCV(SGDClassifier(), param_grid=param_grid, cv=cross_v, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2', 'elasticnet'], 'loss': ('log', 'hinge'), 'alpha': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit model to the data\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.88819, std: 0.02382, params: {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0001},\n",
       " mean: 0.89826, std: 0.01197, params: {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0001},\n",
       " mean: 0.84380, std: 0.04515, params: {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0001},\n",
       " mean: 0.74550, std: 0.24252, params: {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001},\n",
       " mean: 0.89636, std: 0.03074, params: {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0001},\n",
       " mean: 0.89873, std: 0.01271, params: {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0001},\n",
       " mean: 0.90846, std: 0.01088, params: {'penalty': 'l1', 'loss': 'log', 'alpha': 0.0005},\n",
       " mean: 0.89948, std: 0.01293, params: {'penalty': 'l2', 'loss': 'log', 'alpha': 0.0005},\n",
       " mean: 0.91458, std: 0.00814, params: {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0005},\n",
       " mean: 0.89957, std: 0.01394, params: {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0005},\n",
       " mean: 0.90161, std: 0.01222, params: {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.0005},\n",
       " mean: 0.89930, std: 0.02000, params: {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.0005},\n",
       " mean: 0.90643, std: 0.01271, params: {'penalty': 'l1', 'loss': 'log', 'alpha': 0.001},\n",
       " mean: 0.91150, std: 0.00809, params: {'penalty': 'l2', 'loss': 'log', 'alpha': 0.001},\n",
       " mean: 0.91038, std: 0.00915, params: {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.001},\n",
       " mean: 0.90935, std: 0.00735, params: {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.001},\n",
       " mean: 0.90379, std: 0.01621, params: {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.001},\n",
       " mean: 0.90756, std: 0.00765, params: {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.001},\n",
       " mean: 0.91037, std: 0.00341, params: {'penalty': 'l1', 'loss': 'log', 'alpha': 0.005},\n",
       " mean: 0.91092, std: 0.00240, params: {'penalty': 'l2', 'loss': 'log', 'alpha': 0.005},\n",
       " mean: 0.91112, std: 0.00364, params: {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.005},\n",
       " mean: 0.91073, std: 0.00148, params: {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.005},\n",
       " mean: 0.90682, std: 0.00803, params: {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.005},\n",
       " mean: 0.91056, std: 0.00113, params: {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.005},\n",
       " mean: 0.90854, std: 0.00213, params: {'penalty': 'l1', 'loss': 'log', 'alpha': 0.01},\n",
       " mean: 0.91037, std: 0.00341, params: {'penalty': 'l2', 'loss': 'log', 'alpha': 0.01},\n",
       " mean: 0.91037, std: 0.00341, params: {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.01},\n",
       " mean: 0.91073, std: 0.00148, params: {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.01},\n",
       " mean: 0.91073, std: 0.00148, params: {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.01},\n",
       " mean: 0.91073, std: 0.00148, params: {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.01},\n",
       " mean: 0.91073, std: 0.00148, params: {'penalty': 'l1', 'loss': 'log', 'alpha': 0.05},\n",
       " mean: 0.90854, std: 0.00213, params: {'penalty': 'l2', 'loss': 'log', 'alpha': 0.05},\n",
       " mean: 0.91073, std: 0.00148, params: {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.05},\n",
       " mean: 0.91073, std: 0.00148, params: {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.05},\n",
       " mean: 0.91073, std: 0.00148, params: {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.05},\n",
       " mean: 0.91073, std: 0.00148, params: {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.05},\n",
       " mean: 0.91073, std: 0.00148, params: {'penalty': 'l1', 'loss': 'log', 'alpha': 0.1},\n",
       " mean: 0.90963, std: 0.00294, params: {'penalty': 'l2', 'loss': 'log', 'alpha': 0.1},\n",
       " mean: 0.91073, std: 0.00148, params: {'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.1},\n",
       " mean: 0.91073, std: 0.00148, params: {'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.1},\n",
       " mean: 0.91073, std: 0.00148, params: {'penalty': 'l2', 'loss': 'hinge', 'alpha': 0.1},\n",
       " mean: 0.91073, std: 0.00148, params: {'penalty': 'elasticnet', 'loss': 'hinge', 'alpha': 0.1}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of the mean scores only\n",
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914582414876\n",
      "{'penalty': 'elasticnet', 'loss': 'log', 'alpha': 0.0005}\n",
      "SGDClassifier(alpha=0.0005, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Classifier using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import fbeta_score\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "#X_train, X_test, y_train, y_test = numpy.asarray(X_train), numpy.asarray(X_test), numpy.asarray(y_train), numpy.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    # Calculates the precision\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Calculates the recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    # Calculates the f-measure, the harmonic mean of precision and recall.\n",
    "    f = 2*(precision(y_true, y_pred)*recall(y_true, y_pred))/(precision(y_true, y_pred)+recall(y_true, y_pred))\n",
    "    #return fbeta_score(y_true, y_pred, beta=1)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_dim=100))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', recall, precision,fmeasure])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kerasModel = KerasClassifier(build_fn=create_model, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = [10]\n",
    "batches = [50]\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Kgrid = GridSearchCV(estimator=kerasModel, param_grid=param_grid,cv=5,scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1s - loss: 0.6185 - acc: 0.8825 - recall: 0.9562 - precision: 0.9214 - fmeasure: 0.9360\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5364 - acc: 0.9194 - recall: 0.9975 - precision: 0.9215 - fmeasure: 0.9577\n",
      "Epoch 3/10\n",
      "0s - loss: 0.4783 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9588\n",
      "Epoch 4/10\n",
      "0s - loss: 0.4342 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9586\n",
      "Epoch 5/10\n",
      "0s - loss: 0.3995 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9590\n",
      "Epoch 6/10\n",
      "0s - loss: 0.3722 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9590\n",
      "Epoch 7/10\n",
      "0s - loss: 0.3513 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9589\n",
      "Epoch 8/10\n",
      "0s - loss: 0.3353 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9583\n",
      "Epoch 9/10\n",
      "0s - loss: 0.3228 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9591\n",
      "Epoch 10/10\n",
      "0s - loss: 0.3134 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9591\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6932 - acc: 0.5576 - recall: 0.5791 - precision: 0.8559 - fmeasure: 0.5920\n",
      "Epoch 2/10\n",
      "0s - loss: 0.6165 - acc: 0.7880 - recall: 0.9911 - precision: 0.7934 - fmeasure: 0.8811\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5749 - acc: 0.7903 - recall: 0.9944 - precision: 0.7941 - fmeasure: 0.8814\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5493 - acc: 0.7903 - recall: 0.9948 - precision: 0.7944 - fmeasure: 0.8818\n",
      "Epoch 5/10\n",
      "0s - loss: 0.5314 - acc: 0.7926 - recall: 0.9971 - precision: 0.7945 - fmeasure: 0.8833\n",
      "Epoch 6/10\n",
      "0s - loss: 0.5183 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8837\n",
      "Epoch 7/10\n",
      "0s - loss: 0.5079 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8854\n",
      "Epoch 8/10\n",
      "0s - loss: 0.5000 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8841\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4938 - acc: 0.7949 - recall: 0.9966 - precision: 0.7960 - fmeasure: 0.8831\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4876 - acc: 0.7926 - recall: 0.9944 - precision: 0.7960 - fmeasure: 0.8836\n",
      "Epoch 1/10\n",
      "0s - loss: 0.6282 - acc: 0.7765 - recall: 0.9514 - precision: 0.8070 - fmeasure: 0.8723\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5637 - acc: 0.8088 - recall: 1.0000 - precision: 0.8088 - fmeasure: 0.8940\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5321 - acc: 0.8088 - recall: 1.0000 - precision: 0.8088 - fmeasure: 0.8927\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5109 - acc: 0.8088 - recall: 1.0000 - precision: 0.8088 - fmeasure: 0.8931\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4948 - acc: 0.8088 - recall: 1.0000 - precision: 0.8088 - fmeasure: 0.8934\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4825 - acc: 0.8088 - recall: 0.9971 - precision: 0.8103 - fmeasure: 0.8935\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4717 - acc: 0.8157 - recall: 0.9972 - precision: 0.8159 - fmeasure: 0.8971\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4629 - acc: 0.8157 - recall: 0.9941 - precision: 0.8174 - fmeasure: 0.8961\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4550 - acc: 0.8157 - recall: 0.9939 - precision: 0.8173 - fmeasure: 0.8963\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4489 - acc: 0.8203 - recall: 0.9913 - precision: 0.8232 - fmeasure: 0.8982\n",
      "Epoch 1/10\n",
      "0s - loss: 0.6051 - acc: 0.8184 - recall: 0.9887 - precision: 0.8258 - fmeasure: 0.8991\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5473 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9053\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5168 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9053\n",
      "Epoch 4/10\n",
      "0s - loss: 0.4963 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9050\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4817 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9048\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4714 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9048\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4642 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9045\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4564 - acc: 0.8230 - recall: 0.9941 - precision: 0.8266 - fmeasure: 0.9024\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4505 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9050\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4457 - acc: 0.8276 - recall: 0.9944 - precision: 0.8307 - fmeasure: 0.9040\n",
      "Epoch 1/10\n",
      "1s - loss: 0.5784 - acc: 0.8230 - recall: 0.9945 - precision: 0.8268 - fmeasure: 0.9020\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5164 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9051\n",
      "Epoch 3/10\n",
      "0s - loss: 0.4897 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9039\n",
      "Epoch 4/10\n",
      "0s - loss: 0.4717 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9052\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4607 - acc: 0.8276 - recall: 0.9973 - precision: 0.8290 - fmeasure: 0.9044\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4513 - acc: 0.8276 - recall: 0.9974 - precision: 0.8294 - fmeasure: 0.9042\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4428 - acc: 0.8299 - recall: 0.9942 - precision: 0.8323 - fmeasure: 0.9055\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4366 - acc: 0.8322 - recall: 0.9941 - precision: 0.8345 - fmeasure: 0.9064\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4318 - acc: 0.8299 - recall: 0.9924 - precision: 0.8345 - fmeasure: 0.9053\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4270 - acc: 0.8322 - recall: 0.9947 - precision: 0.8346 - fmeasure: 0.9070\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6340 - acc: 0.7673 - recall: 0.8186 - precision: 0.9252 - fmeasure: 0.8533\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5405 - acc: 0.9147 - recall: 0.9900 - precision: 0.9229 - fmeasure: 0.9549\n",
      "Epoch 3/10\n",
      "0s - loss: 0.4782 - acc: 0.9194 - recall: 0.9949 - precision: 0.9233 - fmeasure: 0.9575\n",
      "Epoch 4/10\n",
      "0s - loss: 0.4284 - acc: 0.9194 - recall: 0.9973 - precision: 0.9213 - fmeasure: 0.9575\n",
      "Epoch 5/10\n",
      "0s - loss: 0.3909 - acc: 0.9194 - recall: 0.9974 - precision: 0.9214 - fmeasure: 0.9578\n",
      "Epoch 6/10\n",
      "0s - loss: 0.3634 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9583\n",
      "Epoch 7/10\n",
      "0s - loss: 0.3432 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9590\n",
      "Epoch 8/10\n",
      "0s - loss: 0.3272 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9590\n",
      "Epoch 9/10\n",
      "0s - loss: 0.3162 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9583\n",
      "Epoch 10/10\n",
      "0s - loss: 0.3071 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9591\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6045 - acc: 0.7926 - recall: 0.9973 - precision: 0.7946 - fmeasure: 0.8837\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5584 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8838\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5341 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8845\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5174 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8844\n",
      "Epoch 5/10\n",
      "0s - loss: 0.5048 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8853\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4956 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8848\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4881 - acc: 0.7926 - recall: 0.9939 - precision: 0.7955 - fmeasure: 0.8827\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4821 - acc: 0.7949 - recall: 0.9936 - precision: 0.7972 - fmeasure: 0.8832\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4774 - acc: 0.7972 - recall: 0.9941 - precision: 0.7993 - fmeasure: 0.8854\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4722 - acc: 0.7972 - recall: 0.9916 - precision: 0.8013 - fmeasure: 0.8856\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6282 - acc: 0.7788 - recall: 0.9591 - precision: 0.8070 - fmeasure: 0.8731\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5624 - acc: 0.8088 - recall: 1.0000 - precision: 0.8088 - fmeasure: 0.8937\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5293 - acc: 0.8065 - recall: 0.9970 - precision: 0.8082 - fmeasure: 0.8921\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5078 - acc: 0.8088 - recall: 0.9974 - precision: 0.8104 - fmeasure: 0.8929\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4929 - acc: 0.8065 - recall: 0.9970 - precision: 0.8082 - fmeasure: 0.8919\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4816 - acc: 0.8111 - recall: 0.9973 - precision: 0.8120 - fmeasure: 0.8941\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4714 - acc: 0.8134 - recall: 0.9943 - precision: 0.8154 - fmeasure: 0.8953\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4656 - acc: 0.8134 - recall: 0.9941 - precision: 0.8153 - fmeasure: 0.8941\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4581 - acc: 0.8134 - recall: 0.9915 - precision: 0.8168 - fmeasure: 0.8952\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4537 - acc: 0.8157 - recall: 0.9944 - precision: 0.8176 - fmeasure: 0.8969\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6798 - acc: 0.6276 - recall: 0.7073 - precision: 0.7450 - fmeasure: nan\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5970 - acc: 0.8230 - recall: 0.9944 - precision: 0.8267 - fmeasure: 0.9022\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5516 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9052\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5236 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9047\n",
      "Epoch 5/10\n",
      "0s - loss: 0.5037 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9051\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4886 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9047\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.4765 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9042\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4684 - acc: 0.8230 - recall: 0.9947 - precision: 0.8270 - fmeasure: 0.9021\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4606 - acc: 0.8253 - recall: 0.9973 - precision: 0.8273 - fmeasure: 0.9038\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4540 - acc: 0.8276 - recall: 0.9941 - precision: 0.8301 - fmeasure: 0.9038\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6575 - acc: 0.6966 - recall: 0.7774 - precision: 0.8554 - fmeasure: 0.7636\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5843 - acc: 0.8207 - recall: 0.9860 - precision: 0.8292 - fmeasure: 0.9001\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5439 - acc: 0.8184 - recall: 0.9892 - precision: 0.8262 - fmeasure: 0.8994\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5176 - acc: 0.8230 - recall: 0.9947 - precision: 0.8269 - fmeasure: 0.9020\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4997 - acc: 0.8230 - recall: 0.9947 - precision: 0.8269 - fmeasure: 0.9020\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4858 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9052\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4758 - acc: 0.8276 - recall: 0.9973 - precision: 0.8291 - fmeasure: 0.9044\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4673 - acc: 0.8276 - recall: 0.9971 - precision: 0.8290 - fmeasure: 0.9042\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4605 - acc: 0.8322 - recall: 0.9967 - precision: 0.8324 - fmeasure: 0.9061\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4544 - acc: 0.8345 - recall: 0.9919 - precision: 0.8386 - fmeasure: 0.9080\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6014 - acc: 0.8894 - recall: 0.9620 - precision: 0.9205 - fmeasure: 0.9396\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5067 - acc: 0.9171 - recall: 0.9949 - precision: 0.9212 - fmeasure: 0.9564\n",
      "Epoch 3/10\n",
      "0s - loss: 0.4511 - acc: 0.9194 - recall: 0.9976 - precision: 0.9216 - fmeasure: 0.9575\n",
      "Epoch 4/10\n",
      "0s - loss: 0.4103 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9588\n",
      "Epoch 5/10\n",
      "0s - loss: 0.3784 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9589\n",
      "Epoch 6/10\n",
      "0s - loss: 0.3543 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9588\n",
      "Epoch 7/10\n",
      "0s - loss: 0.3369 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9590\n",
      "Epoch 8/10\n",
      "0s - loss: 0.3237 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9588\n",
      "Epoch 9/10\n",
      "0s - loss: 0.3136 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9590\n",
      "Epoch 10/10\n",
      "0s - loss: 0.3061 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9585\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6494 - acc: 0.7396 - recall: 0.9095 - precision: 0.7867 - fmeasure: 0.8349\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5828 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8848\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5486 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8848\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5275 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8854\n",
      "Epoch 5/10\n",
      "0s - loss: 0.5123 - acc: 0.7926 - recall: 0.9973 - precision: 0.7946 - fmeasure: 0.8828\n",
      "Epoch 6/10\n",
      "0s - loss: 0.5014 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8849\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4932 - acc: 0.7903 - recall: 0.9943 - precision: 0.7940 - fmeasure: 0.8820\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4857 - acc: 0.7903 - recall: 0.9943 - precision: 0.7941 - fmeasure: 0.8820\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4799 - acc: 0.7949 - recall: 0.9942 - precision: 0.7977 - fmeasure: 0.8845\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4747 - acc: 0.7949 - recall: 0.9942 - precision: 0.7975 - fmeasure: 0.8840\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6081 - acc: 0.7880 - recall: 0.9720 - precision: 0.8029 - fmeasure: 0.8787\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5490 - acc: 0.8088 - recall: 1.0000 - precision: 0.8088 - fmeasure: 0.8936\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5228 - acc: 0.8088 - recall: 1.0000 - precision: 0.8088 - fmeasure: 0.8934\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5044 - acc: 0.8111 - recall: 1.0000 - precision: 0.8106 - fmeasure: 0.8950\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4912 - acc: 0.8111 - recall: 0.9969 - precision: 0.8116 - fmeasure: 0.8936\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4802 - acc: 0.8180 - recall: 0.9941 - precision: 0.8193 - fmeasure: 0.8975\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4718 - acc: 0.8203 - recall: 0.9973 - precision: 0.8201 - fmeasure: 0.8988\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4640 - acc: 0.8180 - recall: 0.9943 - precision: 0.8194 - fmeasure: 0.8975\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4578 - acc: 0.8180 - recall: 0.9939 - precision: 0.8191 - fmeasure: 0.8973\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4522 - acc: 0.8203 - recall: 0.9888 - precision: 0.8243 - fmeasure: 0.8986\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6228 - acc: 0.8092 - recall: 0.9722 - precision: 0.8276 - fmeasure: 0.8923\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5608 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9054\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5227 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9041\n",
      "Epoch 4/10\n",
      "0s - loss: 0.4953 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9052\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4800 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9040\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4691 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9050\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4605 - acc: 0.8253 - recall: 0.9971 - precision: 0.8271 - fmeasure: 0.9035\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4529 - acc: 0.8253 - recall: 0.9972 - precision: 0.8272 - fmeasure: 0.9040\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4463 - acc: 0.8276 - recall: 0.9973 - precision: 0.8289 - fmeasure: 0.9046\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4423 - acc: 0.8230 - recall: 0.9949 - precision: 0.8271 - fmeasure: 0.9013\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6387 - acc: 0.7770 - recall: 0.9054 - precision: 0.8411 - fmeasure: 0.8567\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5678 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9042\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5268 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9047\n",
      "Epoch 4/10\n",
      "0s - loss: 0.4984 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9045\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4794 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9049\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4660 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9043\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4564 - acc: 0.8276 - recall: 0.9973 - precision: 0.8291 - fmeasure: 0.9049\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4501 - acc: 0.8299 - recall: 0.9973 - precision: 0.8313 - fmeasure: 0.9055\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4433 - acc: 0.8322 - recall: 0.9944 - precision: 0.8340 - fmeasure: 0.9063\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4382 - acc: 0.8368 - recall: 0.9971 - precision: 0.8369 - fmeasure: 0.9097\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6171 - acc: 0.8180 - recall: 0.8799 - precision: 0.9269 - fmeasure: 0.8847\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5160 - acc: 0.9171 - recall: 0.9950 - precision: 0.9213 - fmeasure: 0.9562\n",
      "Epoch 3/10\n",
      "0s - loss: 0.4582 - acc: 0.9194 - recall: 0.9976 - precision: 0.9216 - fmeasure: 0.9575\n",
      "Epoch 4/10\n",
      "0s - loss: 0.4157 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9587\n",
      "Epoch 5/10\n",
      "0s - loss: 0.3821 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9588\n",
      "Epoch 6/10\n",
      "0s - loss: 0.3577 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9590\n",
      "Epoch 7/10\n",
      "0s - loss: 0.3399 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9590\n",
      "Epoch 8/10\n",
      "0s - loss: 0.3269 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9589\n",
      "Epoch 9/10\n",
      "0s - loss: 0.3162 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9590\n",
      "Epoch 10/10\n",
      "0s - loss: 0.3082 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9589\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6333 - acc: 0.7627 - recall: 0.9516 - precision: 0.7928 - fmeasure: 0.8628\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5847 - acc: 0.7811 - recall: 0.9830 - precision: 0.7922 - fmeasure: 0.8752\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5578 - acc: 0.7880 - recall: 0.9905 - precision: 0.7930 - fmeasure: 0.8800\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5402 - acc: 0.7926 - recall: 0.9968 - precision: 0.7943 - fmeasure: 0.8835\n",
      "Epoch 5/10\n",
      "0s - loss: 0.5260 - acc: 0.7926 - recall: 0.9970 - precision: 0.7944 - fmeasure: 0.8836\n",
      "Epoch 6/10\n",
      "0s - loss: 0.5148 - acc: 0.7926 - recall: 0.9972 - precision: 0.7945 - fmeasure: 0.8837\n",
      "Epoch 7/10\n",
      "0s - loss: 0.5052 - acc: 0.7949 - recall: 0.9970 - precision: 0.7964 - fmeasure: 0.8851\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4978 - acc: 0.7972 - recall: 1.0000 - precision: 0.7968 - fmeasure: 0.8862\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4915 - acc: 0.7972 - recall: 0.9942 - precision: 0.7994 - fmeasure: 0.8848\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4859 - acc: 0.7995 - recall: 0.9943 - precision: 0.8015 - fmeasure: 0.8871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1s - loss: 0.6279 - acc: 0.7696 - recall: 0.9510 - precision: 0.8039 - fmeasure: 0.8682\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5697 - acc: 0.8065 - recall: 0.9974 - precision: 0.8085 - fmeasure: 0.8910\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5406 - acc: 0.8088 - recall: 1.0000 - precision: 0.8088 - fmeasure: 0.8940\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5220 - acc: 0.8088 - recall: 1.0000 - precision: 0.8088 - fmeasure: 0.8926\n",
      "Epoch 5/10\n",
      "0s - loss: 0.5080 - acc: 0.8065 - recall: 0.9973 - precision: 0.8084 - fmeasure: 0.8917\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4946 - acc: 0.8134 - recall: 0.9970 - precision: 0.8140 - fmeasure: 0.8957\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4841 - acc: 0.8157 - recall: 0.9970 - precision: 0.8159 - fmeasure: 0.8967\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4749 - acc: 0.8180 - recall: 0.9942 - precision: 0.8193 - fmeasure: 0.8979\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4679 - acc: 0.8157 - recall: 0.9946 - precision: 0.8179 - fmeasure: 0.8962\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4614 - acc: 0.8157 - recall: 0.9912 - precision: 0.8192 - fmeasure: 0.8958\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6567 - acc: 0.6943 - recall: 0.8386 - precision: 0.8164 - fmeasure: 0.8050\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5897 - acc: 0.8230 - recall: 0.9945 - precision: 0.8268 - fmeasure: 0.9022\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5536 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9049\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5288 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9036\n",
      "Epoch 5/10\n",
      "0s - loss: 0.5107 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9047\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4965 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9047\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4847 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9051\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4744 - acc: 0.8253 - recall: 0.9973 - precision: 0.8273 - fmeasure: 0.9040\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4663 - acc: 0.8253 - recall: 0.9974 - precision: 0.8274 - fmeasure: 0.9036\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4584 - acc: 0.8253 - recall: 0.9944 - precision: 0.8288 - fmeasure: 0.9038\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6296 - acc: 0.7609 - recall: 0.8991 - precision: 0.8192 - fmeasure: 0.8519\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5623 - acc: 0.8276 - recall: 0.9973 - precision: 0.8292 - fmeasure: 0.9052\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5285 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9046\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5041 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9055\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4882 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9039\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4753 - acc: 0.8253 - recall: 0.9973 - precision: 0.8272 - fmeasure: 0.9038\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4646 - acc: 0.8276 - recall: 0.9972 - precision: 0.8291 - fmeasure: 0.9050\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4568 - acc: 0.8299 - recall: 0.9972 - precision: 0.8310 - fmeasure: 0.9057\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4484 - acc: 0.8345 - recall: 0.9973 - precision: 0.8352 - fmeasure: 0.9082\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4426 - acc: 0.8322 - recall: 0.9974 - precision: 0.8329 - fmeasure: 0.9072\n",
      "Epoch 1/10\n",
      "1s - loss: 0.5935 - acc: 0.9055 - recall: 0.9798 - precision: 0.9223 - fmeasure: 0.9498\n",
      "Epoch 2/10\n",
      "0s - loss: 0.4956 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9591\n",
      "Epoch 3/10\n",
      "0s - loss: 0.4291 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9589\n",
      "Epoch 4/10\n",
      "0s - loss: 0.3816 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9590\n",
      "Epoch 5/10\n",
      "0s - loss: 0.3509 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9588\n",
      "Epoch 6/10\n",
      "0s - loss: 0.3307 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9589\n",
      "Epoch 7/10\n",
      "0s - loss: 0.3161 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9590\n",
      "Epoch 8/10\n",
      "0s - loss: 0.3055 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9588\n",
      "Epoch 9/10\n",
      "0s - loss: 0.2984 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9582\n",
      "Epoch 10/10\n",
      "0s - loss: 0.2926 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9587\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6086 - acc: 0.7880 - recall: 0.9908 - precision: 0.7932 - fmeasure: 0.8795\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5621 - acc: 0.7926 - recall: 0.9973 - precision: 0.7946 - fmeasure: 0.8833\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5386 - acc: 0.7926 - recall: 0.9974 - precision: 0.7947 - fmeasure: 0.8828\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5228 - acc: 0.7926 - recall: 0.9969 - precision: 0.7943 - fmeasure: 0.8827\n",
      "Epoch 5/10\n",
      "0s - loss: 0.5109 - acc: 0.7926 - recall: 0.9974 - precision: 0.7947 - fmeasure: 0.8836\n",
      "Epoch 6/10\n",
      "0s - loss: 0.5006 - acc: 0.7926 - recall: 0.9973 - precision: 0.7946 - fmeasure: 0.8839\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4926 - acc: 0.7949 - recall: 0.9972 - precision: 0.7962 - fmeasure: 0.8845\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4868 - acc: 0.7995 - recall: 0.9972 - precision: 0.8008 - fmeasure: 0.8859\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4803 - acc: 0.8041 - recall: 0.9972 - precision: 0.8040 - fmeasure: 0.8895\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4762 - acc: 0.7995 - recall: 0.9864 - precision: 0.8063 - fmeasure: 0.8856\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6465 - acc: 0.7189 - recall: 0.8518 - precision: 0.7782 - fmeasure: 0.8072\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5880 - acc: 0.8088 - recall: 1.0000 - precision: 0.8088 - fmeasure: 0.8936\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5546 - acc: 0.8088 - recall: 1.0000 - precision: 0.8088 - fmeasure: 0.8927\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5314 - acc: 0.8088 - recall: 1.0000 - precision: 0.8088 - fmeasure: 0.8939\n",
      "Epoch 5/10\n",
      "0s - loss: 0.5141 - acc: 0.8088 - recall: 1.0000 - precision: 0.8088 - fmeasure: 0.8920\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4993 - acc: 0.8111 - recall: 1.0000 - precision: 0.8104 - fmeasure: 0.8945\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4882 - acc: 0.8134 - recall: 0.9943 - precision: 0.8159 - fmeasure: 0.8959\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4798 - acc: 0.8157 - recall: 0.9941 - precision: 0.8174 - fmeasure: 0.8963\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4728 - acc: 0.8203 - recall: 0.9942 - precision: 0.8220 - fmeasure: 0.8980\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4660 - acc: 0.8203 - recall: 0.9940 - precision: 0.8211 - fmeasure: 0.8986\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6382 - acc: 0.7471 - recall: 0.8795 - precision: 0.8224 - fmeasure: 0.8230\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5572 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9054\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5185 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9052\n",
      "Epoch 4/10\n",
      "0s - loss: 0.4966 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9052\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4823 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9051\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4717 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9051\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4631 - acc: 0.8253 - recall: 0.9974 - precision: 0.8273 - fmeasure: 0.9037\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4559 - acc: 0.8253 - recall: 0.9974 - precision: 0.8273 - fmeasure: 0.9029\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4498 - acc: 0.8230 - recall: 0.9936 - precision: 0.8262 - fmeasure: 0.9015\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4443 - acc: 0.8230 - recall: 0.9945 - precision: 0.8268 - fmeasure: 0.9024\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6474 - acc: 0.7540 - recall: 0.8924 - precision: 0.8200 - fmeasure: 0.8476\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5828 - acc: 0.8253 - recall: 0.9973 - precision: 0.8272 - fmeasure: 0.9032\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5423 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9040\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5139 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9052\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4945 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9050\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4804 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9050\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4692 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9045\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4594 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9054\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4525 - acc: 0.8276 - recall: 0.9974 - precision: 0.8291 - fmeasure: 0.9044\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4450 - acc: 0.8253 - recall: 0.9973 - precision: 0.8272 - fmeasure: 0.9041\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6734 - acc: 0.6498 - recall: 0.6757 - precision: 0.9074 - fmeasure: 0.6979\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5369 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9586\n",
      "Epoch 3/10\n",
      "0s - loss: 0.4577 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9589\n",
      "Epoch 4/10\n",
      "0s - loss: 0.4058 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9586\n",
      "Epoch 5/10\n",
      "0s - loss: 0.3712 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9590\n",
      "Epoch 6/10\n",
      "0s - loss: 0.3456 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9589\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.3277 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9581\n",
      "Epoch 8/10\n",
      "0s - loss: 0.3141 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9587\n",
      "Epoch 9/10\n",
      "0s - loss: 0.3046 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9590\n",
      "Epoch 10/10\n",
      "0s - loss: 0.2973 - acc: 0.9217 - recall: 1.0000 - precision: 0.9217 - fmeasure: 0.9589\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6057 - acc: 0.7949 - recall: 0.9941 - precision: 0.7977 - fmeasure: 0.8842\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5519 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8841\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5254 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8854\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5101 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8851\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4995 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8839\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4914 - acc: 0.7949 - recall: 1.0000 - precision: 0.7949 - fmeasure: 0.8853\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4853 - acc: 0.7926 - recall: 0.9973 - precision: 0.7946 - fmeasure: 0.8837\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4799 - acc: 0.7903 - recall: 0.9915 - precision: 0.7954 - fmeasure: 0.8821\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4748 - acc: 0.7995 - recall: 0.9939 - precision: 0.8011 - fmeasure: 0.8864\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4706 - acc: 0.7995 - recall: 0.9938 - precision: 0.8013 - fmeasure: 0.8864\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6342 - acc: 0.7650 - recall: 0.9157 - precision: 0.8041 - fmeasure: 0.8539\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5756 - acc: 0.8065 - recall: 0.9938 - precision: 0.8093 - fmeasure: 0.8914\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5459 - acc: 0.8065 - recall: 0.9973 - precision: 0.8084 - fmeasure: 0.8925\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5250 - acc: 0.8111 - recall: 1.0000 - precision: 0.8108 - fmeasure: 0.8951\n",
      "Epoch 5/10\n",
      "0s - loss: 0.5073 - acc: 0.8111 - recall: 1.0000 - precision: 0.8108 - fmeasure: 0.8953\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4940 - acc: 0.8134 - recall: 1.0000 - precision: 0.8123 - fmeasure: 0.8954\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4835 - acc: 0.8111 - recall: 0.9938 - precision: 0.8136 - fmeasure: 0.8932\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4741 - acc: 0.8134 - recall: 0.9945 - precision: 0.8152 - fmeasure: 0.8951\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4661 - acc: 0.8134 - recall: 0.9946 - precision: 0.8158 - fmeasure: 0.8954\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4603 - acc: 0.8134 - recall: 0.9948 - precision: 0.8156 - fmeasure: 0.8952\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6153 - acc: 0.8230 - recall: 0.9948 - precision: 0.8270 - fmeasure: 0.9019\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5619 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9039\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5304 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9047\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5089 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9044\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4944 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9048\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4817 - acc: 0.8253 - recall: 0.9973 - precision: 0.8273 - fmeasure: 0.9040\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4712 - acc: 0.8253 - recall: 0.9971 - precision: 0.8271 - fmeasure: 0.9032\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4626 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9050\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4548 - acc: 0.8253 - recall: 0.9971 - precision: 0.8271 - fmeasure: 0.9036\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4495 - acc: 0.8276 - recall: 0.9974 - precision: 0.8290 - fmeasure: 0.9044\n",
      "Epoch 1/10\n",
      "2s - loss: 0.5889 - acc: 0.8115 - recall: 0.9732 - precision: 0.8266 - fmeasure: 0.8928\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5271 - acc: 0.8253 - recall: 0.9972 - precision: 0.8272 - fmeasure: 0.9033\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5005 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9042\n",
      "Epoch 4/10\n",
      "0s - loss: 0.4832 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9054\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4713 - acc: 0.8276 - recall: 1.0000 - precision: 0.8276 - fmeasure: 0.9048\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4618 - acc: 0.8253 - recall: 0.9973 - precision: 0.8273 - fmeasure: 0.9036\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4532 - acc: 0.8253 - recall: 0.9972 - precision: 0.8272 - fmeasure: 0.9041\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4459 - acc: 0.8299 - recall: 0.9973 - precision: 0.8311 - fmeasure: 0.9064\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4402 - acc: 0.8322 - recall: 0.9973 - precision: 0.8330 - fmeasure: 0.9073\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4343 - acc: 0.8322 - recall: 0.9942 - precision: 0.8341 - fmeasure: 0.9059\n",
      "Epoch 1/10\n",
      "1s - loss: 0.6796 - acc: 0.6114 - recall: 0.6635 - precision: 0.6908 - fmeasure: nan\n",
      "Epoch 2/10\n",
      "0s - loss: 0.5911 - acc: 0.8343 - recall: 0.9977 - precision: 0.8357 - fmeasure: 0.9087\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5387 - acc: 0.8361 - recall: 1.0000 - precision: 0.8361 - fmeasure: 0.9105\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5054 - acc: 0.8361 - recall: 1.0000 - precision: 0.8361 - fmeasure: 0.9095\n",
      "Epoch 5/10\n",
      "0s - loss: 0.4820 - acc: 0.8361 - recall: 1.0000 - precision: 0.8361 - fmeasure: 0.9100\n",
      "Epoch 6/10\n",
      "0s - loss: 0.4673 - acc: 0.8361 - recall: 1.0000 - precision: 0.8361 - fmeasure: 0.9096\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4562 - acc: 0.8343 - recall: 0.9980 - precision: 0.8359 - fmeasure: 0.9088\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4481 - acc: 0.8343 - recall: 0.9980 - precision: 0.8359 - fmeasure: 0.9087\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4400 - acc: 0.8343 - recall: 0.9952 - precision: 0.8368 - fmeasure: 0.9083\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4338 - acc: 0.8379 - recall: 0.9957 - precision: 0.8400 - fmeasure: 0.9106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x0000024014BC3BE0>,\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'epochs': [10], 'init': ['glorot_uniform', 'normal', 'uniform'], 'batch_size': [50], 'optimizer': ['rmsprop', 'adam']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kgrid.fit(numpy.asarray(X), numpy.asarray(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.89297, std: 0.11825, params: {'epochs': 10, 'init': 'glorot_uniform', 'optimizer': 'rmsprop', 'batch_size': 50},\n",
       " mean: 0.89399, std: 0.11873, params: {'epochs': 10, 'init': 'glorot_uniform', 'optimizer': 'adam', 'batch_size': 50},\n",
       " mean: 0.89491, std: 0.11902, params: {'epochs': 10, 'init': 'normal', 'optimizer': 'rmsprop', 'batch_size': 50},\n",
       " mean: 0.89292, std: 0.11846, params: {'epochs': 10, 'init': 'normal', 'optimizer': 'adam', 'batch_size': 50},\n",
       " mean: 0.89499, std: 0.11923, params: {'epochs': 10, 'init': 'uniform', 'optimizer': 'rmsprop', 'batch_size': 50},\n",
       " mean: 0.89499, std: 0.11923, params: {'epochs': 10, 'init': 'uniform', 'optimizer': 'adam', 'batch_size': 50}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of the mean scores only\n",
    "Kgrid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89499489684\n",
      "{'epochs': 10, 'init': 'uniform', 'optimizer': 'rmsprop', 'batch_size': 50}\n",
      "<keras.wrappers.scikit_learn.KerasClassifier object at 0x000002402BD227F0>\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(Kgrid.best_score_)\n",
    "print(Kgrid.best_params_)\n",
    "print(Kgrid.best_estimator_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup 5-fold stratified cross validation\n",
    "#cross_v = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: \n",
      "linear\n",
      "[mean: 0.91073, std: 0.00148, params: {'C': 0.001, 'gamma': 0.001}, mean: 0.91073, std: 0.00148, params: {'C': 0.001, 'gamma': 0.01}, mean: 0.91073, std: 0.00148, params: {'C': 0.001, 'gamma': 0.1}, mean: 0.91073, std: 0.00148, params: {'C': 0.001, 'gamma': 1}, mean: 0.91073, std: 0.00148, params: {'C': 0.01, 'gamma': 0.001}, mean: 0.91073, std: 0.00148, params: {'C': 0.01, 'gamma': 0.01}, mean: 0.91073, std: 0.00148, params: {'C': 0.01, 'gamma': 0.1}, mean: 0.91073, std: 0.00148, params: {'C': 0.01, 'gamma': 1}, mean: 0.91073, std: 0.00148, params: {'C': 0.1, 'gamma': 0.001}, mean: 0.91073, std: 0.00148, params: {'C': 0.1, 'gamma': 0.01}, mean: 0.91073, std: 0.00148, params: {'C': 0.1, 'gamma': 0.1}, mean: 0.91073, std: 0.00148, params: {'C': 0.1, 'gamma': 1}, mean: 0.91073, std: 0.00148, params: {'C': 1, 'gamma': 0.001}, mean: 0.91073, std: 0.00148, params: {'C': 1, 'gamma': 0.01}, mean: 0.91073, std: 0.00148, params: {'C': 1, 'gamma': 0.1}, mean: 0.91073, std: 0.00148, params: {'C': 1, 'gamma': 1}, mean: 0.90380, std: 0.01263, params: {'C': 10, 'gamma': 0.001}, mean: 0.90380, std: 0.01263, params: {'C': 10, 'gamma': 0.01}, mean: 0.90380, std: 0.01263, params: {'C': 10, 'gamma': 0.1}, mean: 0.90380, std: 0.01263, params: {'C': 10, 'gamma': 1}]\n",
      "0.910730197904\n",
      "{'C': 0.001, 'gamma': 0.001}\n",
      "SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.001, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "[[ 89   0]\n",
      " [  0 454]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: \n",
      "poly\n",
      "[mean: 0.91073, std: 0.00148, params: {'C': 0.001, 'gamma': 0.001}, mean: 0.91073, std: 0.00148, params: {'C': 0.001, 'gamma': 0.01}, mean: 0.91073, std: 0.00148, params: {'C': 0.001, 'gamma': 0.1}, mean: 0.90964, std: 0.00073, params: {'C': 0.001, 'gamma': 1}, mean: 0.91073, std: 0.00148, params: {'C': 0.01, 'gamma': 0.001}, mean: 0.91073, std: 0.00148, params: {'C': 0.01, 'gamma': 0.01}, mean: 0.91073, std: 0.00148, params: {'C': 0.01, 'gamma': 0.1}, mean: 0.90726, std: 0.00349, params: {'C': 0.01, 'gamma': 1}, mean: 0.91073, std: 0.00148, params: {'C': 0.1, 'gamma': 0.001}, mean: 0.91073, std: 0.00148, params: {'C': 0.1, 'gamma': 0.01}, mean: 0.91073, std: 0.00148, params: {'C': 0.1, 'gamma': 0.1}, mean: 0.90334, std: 0.00449, params: {'C': 0.1, 'gamma': 1}, mean: 0.91073, std: 0.00148, params: {'C': 1, 'gamma': 0.001}, mean: 0.91073, std: 0.00148, params: {'C': 1, 'gamma': 0.01}, mean: 0.90964, std: 0.00073, params: {'C': 1, 'gamma': 0.1}, mean: 0.90266, std: 0.01078, params: {'C': 1, 'gamma': 1}, mean: 0.91073, std: 0.00148, params: {'C': 10, 'gamma': 0.001}, mean: 0.91073, std: 0.00148, params: {'C': 10, 'gamma': 0.01}, mean: 0.90726, std: 0.00349, params: {'C': 10, 'gamma': 0.1}, mean: 0.89486, std: 0.01395, params: {'C': 10, 'gamma': 1}]\n",
      "0.910730197904\n",
      "{'C': 0.001, 'gamma': 0.001}\n",
      "SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.001, kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "[[ 89   0]\n",
      " [  0 454]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create SVM classifier \n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "\n",
    "# fit the model\n",
    "for kernel in ('linear', 'poly', 'rbf'):\n",
    "    gs = GridSearchCV(svm.SVC(kernel=kernel, gamma='auto'), param_grid=param_grid, cv=StratifiedKFold(n_splits=5), scoring='f1')\n",
    "    gs.fit(X, y)\n",
    "    \n",
    "        \n",
    "    #To see predicted values, for confusion matrix\n",
    "    y1_pred = clf.best_estimator_.predict(X)\n",
    "    \n",
    "    # examine the best model\n",
    "    print('Kernel: ' )\n",
    "    print(kernel)\n",
    "    print(gs.grid_scores_) # create a list of the mean scores only\n",
    "    print(gs.best_score_)\n",
    "    print(gs.best_params_)\n",
    "    print(gs.best_estimator_)\n",
    "    print(confusion_matrix(y, y1_pred))\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
